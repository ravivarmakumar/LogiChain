{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jma1wjIJeyyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a62f87af-b799-412e-fa64-eaf9dfc5ac54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-aiplatform==1.44.0\n",
            "  Downloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.1.12\n",
            "  Downloading langchain-0.1.12-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-vertexai==0.1.1\n",
            "  Downloading langchain_google_vertexai-0.1.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions==4.9.0\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.44.0) (2.0.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.12)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.12)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.28 (from langchain==0.1.12)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.31 (from langchain==0.1.12)\n",
            "  Downloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.12)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.12)\n",
            "  Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.12) (8.2.3)\n",
            "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform==1.44.0)\n",
            "  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-protobuf<5.0.0.0,>=4.24.0.4 (from langchain-google-vertexai==0.1.1)\n",
            "  Downloading types_protobuf-4.25.0.20240417-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0,>=2.31.0 (from langchain-google-vertexai==0.1.1)\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.12)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.12)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.44.0) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.44.0) (1.62.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.44.0) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.44.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.44.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.44.0) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.44.0) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.44.0) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.44.0) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.44.0) (0.13.0)\n",
            "INFO: pip is looking at multiple versions of google-cloud-storage to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform==1.44.0)\n",
            "  Downloading google_cloud_storage-2.15.0-py2.py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.44.0) (1.5.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.12)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging>=14.3 (from google-cloud-aiplatform==1.44.0)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.12) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.12) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.12) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.12) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.12) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.12) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.12) (3.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.44.0) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.44.0) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.12)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: typing_extensions, types-requests, types-protobuf, packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, dataclasses-json, langsmith, langchain-core, google-cloud-storage, langchain-text-splitters, langchain-community, google-cloud-aiplatform, langchain-google-vertexai, langchain\n",
            "\u001b[33m  WARNING: The script langsmith is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.4 google-cloud-aiplatform-1.44.0 google-cloud-storage-2.14.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.12 langchain-community-0.0.34 langchain-core-0.1.45 langchain-google-vertexai-0.1.1 langchain-text-splitters-0.0.1 langsmith-0.1.49 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 types-protobuf-4.25.0.20240417 types-requests-2.31.0.20240406 typing-inspect-0.9.0 typing_extensions-4.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "873a6c302398433c8469cf9e9af07c85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev tesseract-ocr\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 6 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 8,560 kB of archives.\n",
            "After this operation, 31.6 MB of additional disk space will be used.\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libarchive-dev_3.6.0-1ubuntu1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../1-libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../2-libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../3-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../4-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../5-tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121932 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting unstructured==0.12.4\n",
            "  Downloading unstructured-0.12.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m291.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image==1.17.0\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Collecting pytesseract==0.3.10\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting pdfminer.six==20221105\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.4) (5.2.0)\n",
            "Collecting filetype (from unstructured==0.12.4)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured==0.12.4)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.4) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.4) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.4) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.4) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.4) (4.12.3)\n",
            "Collecting emoji (from unstructured==0.12.4)\n",
            "  Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dataclasses-json in /root/.local/lib/python3.10/site-packages (from unstructured==0.12.4) (0.6.4)\n",
            "Collecting python-iso639 (from unstructured==0.12.4)\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured==0.12.4)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.4) (1.25.2)\n",
            "Collecting rapidfuzz (from unstructured==0.12.4)\n",
            "  Downloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured==0.12.4)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /root/.local/lib/python3.10/site-packages (from unstructured==0.12.4) (4.9.0)\n",
            "Collecting unstructured-client>=0.15.1 (from unstructured==0.12.4)\n",
            "  Downloading unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured==0.12.4) (1.14.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image==1.17.0) (9.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /root/.local/lib/python3.10/site-packages (from pytesseract==0.3.10) (23.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.4) (2024.2.2)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client>=0.15.1->unstructured==0.12.4)\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=3.4 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.4) (3.7)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client>=0.15.1->unstructured==0.12.4)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: marshmallow>=3.19.0 in /root/.local/lib/python3.10/site-packages (from unstructured-client>=0.15.1->unstructured==0.12.4) (3.21.1)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /root/.local/lib/python3.10/site-packages (from unstructured-client>=0.15.1->unstructured==0.12.4) (1.0.0)\n",
            "Collecting pypdf>=4.0 (from unstructured-client>=0.15.1->unstructured==0.12.4)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.4) (2.8.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.4) (1.16.0)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /root/.local/lib/python3.10/site-packages (from unstructured-client>=0.15.1->unstructured==0.12.4) (0.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured==0.12.4) (2.0.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.12.4) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.12.4) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.12.4) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.12.4) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.12.4) (4.66.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105) (2.22)\n",
            "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client>=0.15.1->unstructured==0.12.4)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=59bef2fd69a6c05bc54d6cf56c458a64fc91bbee0fcaae38f91df4a31b199a5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pytesseract, pypdf, pdf2image, ordered-set, langdetect, jsonpath-python, emoji, backoff, deepdiff, unstructured-client, pdfminer.six, unstructured\n",
            "\u001b[33m  WARNING: The script filetype is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script pytesseract is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script deep is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script unstructured-ingest is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 deepdiff-7.0.1 emoji-2.11.1 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 ordered-set-4.1.0 pdf2image-1.17.0 pdfminer.six-20221105 pypdf-4.2.0 pytesseract-0.3.10 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.8.1 unstructured-0.12.4 unstructured-client-0.22.0\n",
            "Collecting pillow-heif==0.15.0\n",
            "  Downloading pillow_heif-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.9.0.80\n",
            "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured-inference==0.7.24\n",
            "  Downloading unstructured_inference-0.7.24-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pikepdf==8.13.0\n",
            "  Downloading pikepdf-8.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf==4.0.1\n",
            "  Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.2.0 in /usr/local/lib/python3.10/dist-packages (from pillow-heif==0.15.0) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.9.0.80) (1.25.2)\n",
            "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.7.24)\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart (from unstructured-inference==0.7.24)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.24) (0.20.3)\n",
            "Collecting onnx (from unstructured-inference==0.7.24)\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime<1.16 (from unstructured-inference==0.7.24)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.24) (4.40.0)\n",
            "Requirement already satisfied: rapidfuzz in /root/.local/lib/python3.10/site-packages (from unstructured-inference==0.7.24) (3.8.1)\n",
            "Collecting pillow>=9.2.0 (from pillow-heif==0.15.0)\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pikepdf==8.13.0)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /root/.local/lib/python3.10/site-packages (from pikepdf==8.13.0) (23.2)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.10/dist-packages (from pikepdf==8.13.0) (4.9.4)\n",
            "Collecting coloredlogs (from onnxruntime<1.16->unstructured-inference==0.7.24)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.24) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.24) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.24) (1.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.24) (3.13.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.24) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.24) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.24) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.24) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.24) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.24) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured-inference==0.7.24) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.local/lib/python3.10/site-packages (from huggingface-hub->unstructured-inference==0.7.24) (4.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pikepdf==8.13.0) (1.14.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2.0.3)\n",
            "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pdf2image in /root/.local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (1.17.0)\n",
            "Requirement already satisfied: pytesseract in /root/.local/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (0.3.10)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (0.17.1+cu121)\n",
            "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<1.16->unstructured-inference==0.7.24)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2.0.7)\n",
            "Collecting omegaconf>=2.0 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2024.1)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading pypdfium2-4.29.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (42.0.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->unstructured-inference==0.7.24) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->unstructured-inference==0.7.24) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->unstructured-inference==0.7.24) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<1.16->unstructured-inference==0.7.24) (1.3.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (3.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2.1.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (3.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.24) (2.22)\n",
            "Building wheels for collected packages: iopath, antlr4-python3-runtime\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=d3ceda6786515e204e4c6bbb8702b5bdc562fda46811097152a6b5b0a74ab132\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=cf42759e42aad3bf7dde63608ff1a6e868f496181315a4fe475c00e9bcc23d6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built iopath antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, python-multipart, pypdfium2, pypdf, portalocker, pillow, opencv-python, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, Deprecated, pillow-heif, pikepdf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, coloredlogs, pdfminer.six, onnxruntime, nvidia-cusolver-cu12, pdfplumber, layoutparser, timm, effdet, unstructured-inference\n",
            "\u001b[33m  WARNING: The script pypdfium2 is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Attempting uninstall: pypdf\n",
            "    Found existing installation: pypdf 4.2.0\n",
            "    Uninstalling pypdf-4.2.0:\n",
            "      Successfully uninstalled pypdf-4.2.0\n",
            "\u001b[33m  WARNING: The scripts backend-test-tools, check-model and check-node are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script humanfriendly is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Attempting uninstall: pdfminer.six\n",
            "    Found existing installation: pdfminer.six 20221105\n",
            "    Uninstalling pdfminer.six-20221105:\n",
            "      Successfully uninstalled pdfminer.six-20221105\n",
            "\u001b[33m  WARNING: The script onnxruntime_test is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script pdfplumber is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 effdet-0.4.1 humanfriendly-10.0 iopath-0.1.10 layoutparser-0.3.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 onnx-1.16.0 onnxruntime-1.15.1 opencv-python-4.9.0.80 pdfminer.six-20231228 pdfplumber-0.11.0 pikepdf-8.13.0 pillow-10.3.0 pillow-heif-0.15.0 portalocker-2.8.2 pypdf-4.0.1 pypdfium2-4.29.0 python-multipart-0.0.9 timm-0.9.16 unstructured-inference-0.7.24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              },
              "id": "dfbc89d601e048758d5ec8b926e780fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_hub==0.16.1 in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Collecting tensorflow_text==2.15.0\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub==0.16.1) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub==0.16.1) (3.20.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub==0.16.1) (2.15.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /root/.local/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /root/.local/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0) (3.2.2)\n",
            "Installing collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.15.0\n"
          ]
        }
      ],
      "source": [
        "# Install Vertex AI LLM SDK\n",
        "! pip install --user --upgrade google-cloud-aiplatform==1.44.0 langchain==0.1.12 langchain-google-vertexai==0.1.1 typing_extensions==4.9.0\n",
        "\n",
        "# Dependencies required by Unstructured PDF loader\n",
        "! sudo apt -y -qq install tesseract-ocr libtesseract-dev\n",
        "! sudo apt-get -y -qq install poppler-utils\n",
        "! pip install --user --upgrade unstructured==0.12.4 pdf2image==1.17.0 pytesseract==0.3.10 pdfminer.six==20221105\n",
        "! pip install --user --upgrade pillow-heif==0.15.0 opencv-python==4.9.0.80 unstructured-inference==0.7.24 pikepdf==8.13.0 pypdf==4.0.1\n",
        "\n",
        "# For Matching Engine integration dependencies (default embeddings)\n",
        "! pip install --user --upgrade tensorflow_hub==0.16.1 tensorflow_text==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Phase I: Install, Set Up, and Develop Q&A Search Ecosystem"
      ],
      "metadata": {
        "id": "owieWr7249PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically restart kernel so that the system can access newly-installed packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "A3YHP1Tcikp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9ebb0a-6957-4b42-fa7f-532bb69d24a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell should ideally check session state and proceed accordingly\n",
        "print(\"This cell might not run correctly if the kernel was just restarted. Manually execute cells sequentially after a restart.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCdJTAoDxU5J",
        "outputId": "0bd8c94b-8c43-4125-af79-24621a390d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This cell might not run correctly if the kernel was just restarted. Manually execute cells sequentially after a restart.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication of Google Account\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "  from google.colab import auth\n",
        "\n",
        "  auth.authenticate_user()"
      ],
      "metadata": {
        "id": "-JSBP_aYjQ1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Python Modules for accessing Vertex AI Matching Engine\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(\"utils\"):\n",
        "  os.makedirs(\"utils\")\n",
        "\n",
        "urlprefix = \"https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/use-cases/document-qa/utils\"\n",
        "files = [\"__init__.py\", \"matching_engine.py\", \"matching_engine_utils.py\"]\n",
        "\n",
        "for fname in files:\n",
        "  urllib.request.urlretrieve(f\"{urlprefix}/{fname}\", filename=f\"utils/{fname}\")"
      ],
      "metadata": {
        "id": "Sj7oYDaekCtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bigframes.dataframe"
      ],
      "metadata": {
        "id": "PbQTHJ5K3fbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import json\n",
        "import textwrap\n",
        "\n",
        "# Utils\n",
        "import time\n",
        "import uuid\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import vertexai\n",
        "\n",
        "# Vertex AI\n",
        "from google.cloud import aiplatform\n",
        "print(f\"Vertex AI SDK Version: {aiplatform.__version__}\")\n",
        "\n",
        "# LangChain\n",
        "import langchain\n",
        "print(f\"LangChain version: {langchain.__version__}\")\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import GCSDirectoryLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Import custom Matching Engine packages\n",
        "from utils.matching_engine import MatchingEngine\n",
        "from utils.matching_engine_utils import MatchingEngineUtils"
      ],
      "metadata": {
        "id": "wqqqudCmq7VP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e518ea7c-7c82-49ef-be4e-9f00e5120087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertex AI SDK Version: 1.44.0\n",
            "LangChain version: 0.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"amplified-time-418915\" # @param {type:\"string\"}\n",
        "REGION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "# Initialize Vertex AI SDK\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ],
      "metadata": {
        "id": "RjQ6d25Egmip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Custom Vertex AI Embeddings\n",
        "\n",
        "# Funtion to limit the rate for Embeddings API\n",
        "def rate_limit(max_per_minute):\n",
        "  period = 60 / max_per_minute\n",
        "  print(\"Waiting\")\n",
        "  while True:\n",
        "    before = time.time()\n",
        "    yield\n",
        "    after = time.time()\n",
        "    elapsed = after - before\n",
        "    sleep_time = max(0, period - elapsed)\n",
        "    if sleep_time > 0:\n",
        "      print(\".\",end=\"\")\n",
        "      time.sleep(sleep_time)\n",
        "\n",
        "# Class to perform vector embeddings using Vertex AI services\n",
        "# Class CustomVertexAIEmbeddings: child of class VertexAIEmbeddings\n",
        "# Class VertexAIEmbeddings: LangChain's wrapper around GCP Vertex AI text embedding models API\n",
        "# This class handles vector embeddings using GCP: Vertex AI services and technologies\n",
        "\n",
        "class CustomVertexAIEmbeddings(VertexAIEmbeddings):\n",
        "  requests_per_minute: int\n",
        "  num_instances_per_batch: int\n",
        "\n",
        "  # Overriding embed_documents method\n",
        "  def embed_documents(self, texts: List[str]):\n",
        "    limiter = rate_limit(self.requests_per_minute)\n",
        "    results = []\n",
        "    docs = list(texts)\n",
        "\n",
        "    while docs:\n",
        "      # Working in batches because the API accepts maximum 5 documents per request to get embeddings\n",
        "      head, docs = (\n",
        "          docs[: self.num_instances_per_batch],\n",
        "          docs[self.num_instances_per_batch :],\n",
        "      )\n",
        "      chunk = self.client.get_embeddings(head)\n",
        "      results.extend(chunk)\n",
        "      next(limiter)\n",
        "\n",
        "    return [r.values for r in results]"
      ],
      "metadata": {
        "id": "xUoJ1WexqnN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Embeddings Instance and LLM Instance\n",
        "\n",
        "# Text model instance integrated with LangChain\n",
        "# Create GEMINI LLM using LangChain's VertexAI class API\n",
        "\n",
        "llm = VertexAI(\n",
        "    model_name=\"gemini-1.0-pro\",\n",
        "    max_output_tokens=2048,\n",
        "    temperature=0.5,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Embeddings API integrated with langchain\n",
        "# Create an instance, named \"embeddings\", of class CustomVertexAIEmbeddings\n",
        "# This instance can handle 100 requests/queries per minute (QPM)\n",
        "\n",
        "EMBEDDING_QPM = 100\n",
        "EMBEDDING_NUM_BATCH = 5\n",
        "embeddings = CustomVertexAIEmbeddings(\n",
        "    requests_per_minute=EMBEDDING_QPM,\n",
        "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
        ")"
      ],
      "metadata": {
        "id": "BSHRHI-jqnL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01ee2d3-bf3b-4455-dec9-ac71b3319b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `VertexAI` was deprecated in LangChain 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAI`.\n",
            "  warn_deprecated(\n",
            "WARNING:langchain_community.embeddings.vertexai:Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Phase II: Develop and Test Q&A – Search System"
      ],
      "metadata": {
        "id": "GSn7i1h65HBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matching Engine Index and Endpoint: Specify Parameters\n",
        "\n",
        "ME_REGION = \"us-central1\"\n",
        "ME_INDEX_NAME = f\"{PROJECT_ID}-me-logimind-index\" # @param {type:\"string\"}\n",
        "ME_EMBEDDING_DIR = f\"{PROJECT_ID}-me-logimind-bucket\" # @param {type:\"string\"}\n",
        "ME_DIMENSIONS = 768 # For gemini 1.0 pro, same as using Vertex PaLM Embedding"
      ],
      "metadata": {
        "id": "ikcvUBYF2Qzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matching Engine Index and Endpoint: Create GCP Cloud Storage Buckets\n",
        "\n",
        "! set -x && gsutil mb -p $PROJECT_ID -l us-central1 gs://$ME_EMBEDDING_DIR"
      ],
      "metadata": {
        "id": "dUV17KHzqnJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b36c5d4-7ea0-4433-b75a-d2d9e00844e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ gsutil mb -p amplified-time-418915 -l us-central1 gs://amplified-time-418915-me-logimind-bucket\n",
            "Creating gs://amplified-time-418915-me-logimind-bucket/...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Newly-Created Matching Engine Index Folder with Dummy Embeddings File\n",
        "\n",
        "# dummy embeddings\n",
        "init_embedding = {\"id\": str(uuid.uuid4()), \"embedding\": list(np.zeros(ME_DIMENSIONS))}\n",
        "\n",
        "# Save dummy embeddings to a local JSON file\n",
        "with open(\"embedding_0.json\",\"w\") as f:\n",
        "  json.dump(init_embedding, f)\n",
        "\n",
        "# Upload the dummy embedding JSON file to cloud storage buckets\n",
        "! set -x && gsutil cp embedding_0.json gs://{ME_EMBEDDING_DIR}/init_index/init_embedding_0.json"
      ],
      "metadata": {
        "id": "zJ9ngHZ_7Erx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd62f514-79bd-4c3c-b6a0-bb4a9c5f3f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ gsutil cp embedding_0.json gs://amplified-time-418915-me-logimind-bucket/init_index/init_embedding_0.json\n",
            "Copying file://embedding_0.json [Content-Type=application/json]...\n",
            "/ [1 files][  3.8 KiB/  3.8 KiB]                                                \n",
            "Operation completed over 1 objects/3.8 KiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Matching Engine\n",
        "mengine = MatchingEngineUtils(PROJECT_ID, ME_REGION, ME_INDEX_NAME)"
      ],
      "metadata": {
        "id": "ITBIENfZ7Eo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Matching Engine Index\n",
        "\n",
        "# Invoke the method create_index of the Matching Engine to create the index\n",
        "index = mengine.create_index(\n",
        "    embedding_gcs_uri=f\"gs://{ME_EMBEDDING_DIR}/init_index\",\n",
        "    dimensions=ME_DIMENSIONS,\n",
        "    index_update_method=\"streaming\",\n",
        "    index_algorithm=\"tree-ah\",\n",
        ")\n",
        "\n",
        "if index:\n",
        "  print(index.name)"
      ],
      "metadata": {
        "id": "vSjioADh7EgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19c7d4f-cc8f-426a-99a4-9e4f3de22962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".projects/429987130664/locations/us-central1/indexes/7885473094037405696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy ME (or Vector Search Engine - VSE) Index to the endpoint\n",
        "\n",
        "# Create an ME (or VSE) endpoint\n",
        "# Then, deploy the ME (or VSE) index to the newly created endpoint\n",
        "index_endpoint = mengine.deploy_index()\n",
        "\n",
        "if index_endpoint:\n",
        "  print(f\"Index endpoint resource name: {index_endpoint.name}\")\n",
        "  print(\n",
        "      f\"Index endpoint public domain name: {index_endpoint.public_endpoint_domain_name}\"\n",
        "  )\n",
        "  print(\"Deployed indexes on the index endpoint: \")\n",
        "\n",
        "  for d in index_endpoint.deployed_indexes:\n",
        "    print(f\"    {d.id}\")"
      ],
      "metadata": {
        "id": "MxEYWWL97EeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cd4e63-9c2f-4ac1-a66b-7451ca7f6692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "..................Index endpoint resource name: projects/429987130664/locations/us-central1/indexEndpoints/3638015695473606656\n",
            "Index endpoint public domain name: \n",
            "Deployed indexes on the index endpoint: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest and pre-process the PDF files\n",
        "\n",
        "# adta5760-docs-folder-1 is the name of the GCP cloud storage bucket\n",
        "# adta5760-docs-folder-1 --> subfolder: documents\n",
        "# documents --> subfolder: pdfs\n",
        "# pdfs: The subfolder where all the PDFs are stored\n",
        "GCS_BUCKET_DOCS = f\"adta5760-docs-folder-2\"\n",
        "\n",
        "folder_prefix = \"documents/pdfs\"\n",
        "\n",
        "print(f\"Processing documents from {GCS_BUCKET_DOCS}\")\n",
        "\n",
        "# Load all the PDFs to be processed into the system\n",
        "# First, create a loader to upload the entire folder (or directory)\n",
        "loader = GCSDirectoryLoader(\n",
        "    project_name=PROJECT_ID, bucket=GCS_BUCKET_DOCS, prefix=folder_prefix\n",
        ")\n",
        "\n",
        "# Then, load all PDFs into the knowledge base metadata named \"documents\"\n",
        "documents = loader.load()\n",
        "\n",
        "# Add document name and source to the metadata\n",
        "for document in documents:\n",
        "  doc_md = document.metadata\n",
        "  document_name = doc_md[\"source\"].split(\"/\")[-1]\n",
        "\n",
        "  # derive doc source from Document loader\n",
        "  doc_source_prefix = \"/\".join(GCS_BUCKET_DOCS.split(\"/\")[:3])\n",
        "  doc_source_suffix = \"/\".join(doc_md[\"source\"].split(\"/\")[4:-1])\n",
        "  source = f\"{doc_source_prefix}/{doc_source_suffix}\"\n",
        "  document.metadata = {\"source\": source, \"document_name\": document_name}\n",
        "\n",
        "print(f\"# of documents loaded (pre-chunking) = {len(documents)}\")"
      ],
      "metadata": {
        "id": "7J-Iwsu27Eb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e68c98c-91b5-448d-be24-fd5ee0d1cb5f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing documents from adta5760-docs-folder-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `GCSDirectoryLoader` was deprecated in LangChain 0.0.32 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-community package and should be used instead. To use it run `pip install -U langchain-google-community` and import as `from langchain_google_community import GCSDirectoryLoader`.\n",
            "  warn_deprecated(\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents loaded (pre-chunking) = 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the metadata of the first PDF in the knowledge base\n",
        "\n",
        "documents[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNrhC8koBOMr",
        "outputId": "f6ef9614-27c1-40f7-ddbb-b4aa7a7a3b36"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'adta5760-docs-folder-2/pdfs',\n",
              " 'document_name': 'An Investigation of Visibility and Flexibility as complements to supply chain analytics.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the documents into chunks\n",
        "# Using LangChain's Document Transformer function RecursiveCharacterTextSplitter()\n",
        "# RecursiveCharacterTextSplitter: Recursively Split by Characters\n",
        "\n",
        "# Create a Langchain's document transformer to split text documents into smaller chunks\n",
        "# Using the function RecursiveCharacterTextSplitter()\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 50,\n",
        "    separators = [\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
        ")\n",
        "\n",
        "# Split documents using the text splitter\n",
        "doc_splits = text_splitter.split_documents(documents)\n",
        "\n",
        "# Add chunk number to a document's metadata\n",
        "for idx, split in enumerate(doc_splits):\n",
        "  split.metadata[\"chunk\"] = idx\n",
        "\n",
        "print(f\"# of document splits = {len(doc_splits)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYP6yL_tBOA3",
        "outputId": "629d8c77-cf6e-47e6-8ded-74c39094ab86"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of document splits = 3190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the split data realted to the first document\n",
        "\n",
        "doc_splits[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG27X58FBuZV",
        "outputId": "cbf8b324-ff67-4065-ad9e-a2a3e74a2456"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'adta5760-docs-folder-2/pdfs',\n",
              " 'document_name': 'An Investigation of Visibility and Flexibility as complements to supply chain analytics.pdf',\n",
              " 'chunk': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Matching Engine (or Vector Search Engine) Index ID and Endpoint ID\n",
        "\n",
        "ME_INDEX_ID, ME_INDEX_ENDPOINT_ID = mengine.get_index_and_endpoint()\n",
        "\n",
        "print(f\"ME_INDEX_ID={ME_INDEX_ID}\")\n",
        "print(f\"ME_INDEX_ENDPOINT_ID={ME_INDEX_ENDPOINT_ID}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1E72lFWEIZj",
        "outputId": "7719f30b-14aa-4f89-b771-5678c1cab87f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ME_INDEX_ID=projects/429987130664/locations/us-central1/indexes/7885473094037405696\n",
            "ME_INDEX_ENDPOINT_ID=projects/429987130664/locations/us-central1/indexEndpoints/3638015695473606656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store docs as embeddings in Mactching Engine Index\n",
        "\n",
        "# First, get contents of each document chunk\n",
        "texts = [doc.page_content for doc in doc_splits]\n",
        "\n",
        "# Next, create metadata for each document chunk\n",
        "metadatas = [\n",
        "    [\n",
        "        {\"namespace\": \"source\", \"allow_list\": [doc.metadata[\"source\"]]},\n",
        "        {\"namespace\": \"document_source\", \"allow_list\": [doc.metadata[\"document_name\"]]},\n",
        "        {\"namespace\": \"chunk\", \"allow_list\": [str(doc.metadata[\"chunk\"])]},\n",
        "    ]\n",
        "    for doc in doc_splits\n",
        "]"
      ],
      "metadata": {
        "id": "z_n41KPzEIOn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Matching Engine (or Vector Search Engine) as GCP Vector Store(or Vector Database)\n",
        "\n",
        "# initialize vector store\n",
        "me = MatchingEngine.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=ME_REGION,\n",
        "    gcs_bucket_name=f\"gs://{ME_EMBEDDING_DIR}\".split(\"/\")[2],\n",
        "    embedding=embeddings,\n",
        "    index_id=ME_INDEX_ID,\n",
        "    endpoint_id=ME_INDEX_ENDPOINT_ID,\n",
        ")"
      ],
      "metadata": {
        "id": "mqHY6KHPRHqr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store docs as vector embeddings in Matching Engine (or Vector Search Engine) index\n",
        "# It may take a while since API is rate limited\n",
        "# At least 30 minutes or longer\n",
        "\n",
        "doc_ids = me.add_texts(texts=texts, metadatas=metadatas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZXUUimHGAle",
        "outputId": "77e702a3-46e3-4236-b083-92699fff57b6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting\n",
            "......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify if semantic search with Matching Engine (or Vector Search Engine) is working.\n",
        "# Test 1: k = 2 --> A parameter for ANN (Approximate Nearest Neighbor) vector search\n",
        "# k: similar to K in K-Nearest Neighbor Algorithm\n",
        "\n",
        "me.similarity_search(\"In E-commerce, what are the two types of business models?\", k=2)"
      ],
      "metadata": {
        "id": "8lJ7mPGZGgum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c062078-7af6-4cc7-b083-e95f225345e8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='In the E-commerce LSCM, there are two major types of business models: business to consumer (B2C) and business to business (B2B) (Bolumole et al., 2015). In B2C model, business website is a place where all the transactions take place between a business organization and consumer directly (Mangiaracina et al., 2015). In this model, a consumer visits the website and places an order to buy the products. The business organization, after receiving the orders, will dispatch the goods to the customer. Successful examples like Amazon.com and Priceline.com are B2C leaders (Rappa, 2008; Ta et al., 2015). Key features of this model are heavy advertising required to attract large customers, high investment of hardware and software, and good customer care service (Nica, 2015). B2B refers to a situation where one business makes a commercial transaction with another, thus, the transaction volume of B2B is much higher than the volume of B2C', metadata={'source': 'adta5760-docs-folder-2/pdfs', 'document_source': 'E-commerce_logistics_in_supply.pdf', 'chunk': '1236', 'score': 0.7874481081962585}),\n",
              " Document(page_content='Based on the booming E-commerce, logistics and supply chain management (LSCM) has been greatly influenced when we are now already overwhelmed by its successes in both developed E- commerceLSCM,there are two major types of business models. They are business to consumer (B2C) and business to business (B2B) (Bolumole, Closset al.2015). In B2C model, business website is a place where all the transactions take place between a business organization and consumer directly (Miangiaracina, Marchet et al. 2015). In this model, a consumer visits the website and places an order to buy a catalog. The business organization, after receiving the order, will dispatch the goods to the customer. Successful examples like Amazon.com and Priceline.com are B2C leaders (Rappa 2008, Ta, Esper et al. 2015). Key features of this model are heavy advertising required to attract large customers, high investment of hardware and software, and good customer care service (Nica 2015)', metadata={'source': 'adta5760-docs-folder-2/pdfs', 'document_source': 'E-commerce Logistics in Supply Chain Management.pdf', 'chunk': '1184', 'score': 0.7340328693389893})]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify if semantic search with Matching Engine (or Vector Search Engine) is working.\n",
        "# Test 2: k = 2 --> A parameter for ANN (Approximate Nearest Neighbor) vector search\n",
        "# k: similar to K in K-Nearest Neighbor Algorithm\n",
        "# search_distance: the concept is similar to the distance in K-Nearest Neighbor Algorithm\n",
        "\n",
        "me.similarity_search(\"Give me B2C leaders?\", k=2, search_distance=0.4)"
      ],
      "metadata": {
        "id": "BeNvkPvMHTnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdfa999-035d-47f3-f4eb-a7edac90e546"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='[47]. Ta, H., T. Esper and A. R. Hofer (2015). \"Business(cid:1)to(cid:1)Consumer (B2C) Collaboration: Rethinking the Role of Consumers in Supply Chain Management.\" Journal of Business Logistics 36(1): 133-134. [48]. Tan, K. H., Y. Zhan, G. Ji, F. Ye and C. Chang (2015). \"Harvesting big data to enhance supply chain innovation capabilities: An analytic infrastructure based on deduction graph.\" International Journal of Production Economics 165: 223-233.\\n\\n[31]. Li, J. and J. Ding (2014). \"Research of self-support logistics network synergy route and structure evolution--take SUNING and ZJS for examples.\" Journal of Beijing Jiaotong University(Social Sciences Edition)(03): 46-53.\\n\\n[49]. Timothy Thacher, B. W., Brian Stuorius (2007). Strategic Report For\\n\\nLowe\\'s Companies,Inc.\\n\\n[50]. Trebilcock, B. (2011). IKEA: Think global, act local for warehouse\\n\\ndistribution. Modern Materials Handling. August.\\n\\n[32]. Liu, J. and Y. R. Hou (2011). \"Time based strategy in distribution', metadata={'source': 'adta5760-docs-folder-2/pdfs', 'document_source': 'E-commerce Logistics in Supply Chain Management.pdf', 'chunk': '1228', 'score': 0.7223916053771973}),\n",
              " Document(page_content='In the E-commerce LSCM, there are two major types of business models: business to consumer (B2C) and business to business (B2B) (Bolumole et al., 2015). In B2C model, business website is a place where all the transactions take place between a business organization and consumer directly (Mangiaracina et al., 2015). In this model, a consumer visits the website and places an order to buy the products. The business organization, after receiving the orders, will dispatch the goods to the customer. Successful examples like Amazon.com and Priceline.com are B2C leaders (Rappa, 2008; Ta et al., 2015). Key features of this model are heavy advertising required to attract large customers, high investment of hardware and software, and good customer care service (Nica, 2015). B2B refers to a situation where one business makes a commercial transaction with another, thus, the transaction volume of B2B is much higher than the volume of B2C', metadata={'source': 'adta5760-docs-folder-2/pdfs', 'document_source': 'E-commerce_logistics_in_supply.pdf', 'chunk': '1236', 'score': 0.7116405963897705})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Phase III: Formatting the Retrievel Q&A using LLM"
      ],
      "metadata": {
        "id": "wB0xG9Jx12tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create chain to answer questions\n",
        "NUMBER_OF_RESULTS = 3\n",
        "SEARCH_DISTANCE_THRESHOLD = 0.6"
      ],
      "metadata": {
        "id": "yskBDd-F2JV4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expose index to the retriever\n",
        "retriever = me.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": NUMBER_OF_RESULTS,\n",
        "        \"search_distance\": SEARCH_DISTANCE_THRESHOLD,\n",
        "    },\n",
        "    filters=None,\n",
        ")"
      ],
      "metadata": {
        "id": "bPkdTOa12A3-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"SYSTEM: You are an intelligent assistant and subject matter expert helping the employees with their questions on supply chain industry, especially on the logistics domain.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
        "\n",
        "Do not try to make up an answer:\n",
        " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
        " - If the context is empty, just say \"I do not know the answer to that.\"\n",
        "\n",
        "=============\n",
        "{context}\n",
        "=============\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\""
      ],
      "metadata": {
        "id": "OJrwlPg52OJM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses LLM to synthesize results from the search index.\n",
        "# Use Vertex Gemini Text API for LLM\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    verbose=True,\n",
        "    chain_type_kwargs={\n",
        "        \"prompt\": PromptTemplate(\n",
        "            template=template,\n",
        "            input_variables=[\"context\", \"question\"],\n",
        "        ),\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "C7HjvtQF2Wcn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable for troubleshooting\n",
        "qa.combine_documents_chain.verbose = True\n",
        "qa.combine_documents_chain.llm_chain.verbose = True\n",
        "qa.combine_documents_chain.llm_chain.llm.verbose = True"
      ],
      "metadata": {
        "id": "tUf2GDuh2WaC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatter(result):\n",
        "    print(f\"Query: {result['query']}\")\n",
        "    print(\".\" * 80)\n",
        "    if \"source_documents\" in result.keys():\n",
        "        for idx, ref in enumerate(result[\"source_documents\"]):\n",
        "            print(\"-\" * 80)\n",
        "            print(f\"REFERENCE #{idx}\")\n",
        "            print(\"-\" * 80)\n",
        "            if \"score\" in ref.metadata:\n",
        "                print(f\"Matching Score: {ref.metadata['score']}\")\n",
        "            if \"source\" in ref.metadata:\n",
        "                print(f\"Document Source: {ref.metadata['source']}\")\n",
        "            if \"document_name\" in ref.metadata:\n",
        "                print(f\"Document Name: {ref.metadata['document_name']}\")\n",
        "            print(\".\" * 80)\n",
        "            print(f\"Content: \\n{wrap(ref.page_content)}\")\n",
        "    print(\".\" * 80)\n",
        "    print(f\"Response: {wrap(result['result'])}\")\n",
        "    print(\".\" * 80)\n",
        "\n",
        "\n",
        "def wrap(s):\n",
        "    return \"\\n\".join(textwrap.wrap(s, width=120, break_long_words=False))\n",
        "\n",
        "\n",
        "def ask(\n",
        "    query,\n",
        "    qa=qa,\n",
        "    k=NUMBER_OF_RESULTS,\n",
        "    search_distance=SEARCH_DISTANCE_THRESHOLD,\n",
        "    filters={},\n",
        "):\n",
        "    qa.retriever.search_kwargs[\"search_distance\"] = search_distance\n",
        "    qa.retriever.search_kwargs[\"k\"] = k\n",
        "    qa.retriever.search_kwargs[\"filters\"] = filters\n",
        "    result = qa({\"query\": query})\n",
        "    return formatter(result)"
      ],
      "metadata": {
        "id": "kFzWk-fl2eaG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test Case I"
      ],
      "metadata": {
        "id": "a5X1rQMVNiXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"In E-commerce, what are the two types of business models?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoMBJYgx-dwW",
        "outputId": "e429db56-6e09-41b1-917c-8ed96e0405a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "Waiting\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant and subject matter expert helping the employees with their questions on supply chain industry, especially on the logistics domain.\n",
            "\n",
            "Question: In E-commerce, what are the two types of business models?\n",
            "\n",
            "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
            "\n",
            "Do not try to make up an answer:\n",
            " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
            " - If the context is empty, just say \"I do not know the answer to that.\"\n",
            "\n",
            "=============\n",
            "In the E-commerce LSCM, there are two major types of business models: business to consumer (B2C) and business to business (B2B) (Bolumole et al., 2015). In B2C model, business website is a place where all the transactions take place between a business organization and consumer directly (Mangiaracina et al., 2015). In this model, a consumer visits the website and places an order to buy the products. The business organization, after receiving the orders, will dispatch the goods to the customer. Successful examples like Amazon.com and Priceline.com are B2C leaders (Rappa, 2008; Ta et al., 2015). Key features of this model are heavy advertising required to attract large customers, high investment of hardware and software, and good customer care service (Nica, 2015). B2B refers to a situation where one business makes a commercial transaction with another, thus, the transaction volume of B2B is much higher than the volume of B2C\n",
            "\n",
            "Based on the booming E-commerce, logistics and supply chain management (LSCM) has been greatly influenced when we are now already overwhelmed by its successes in both developed E- commerceLSCM,there are two major types of business models. They are business to consumer (B2C) and business to business (B2B) (Bolumole, Closset al.2015). In B2C model, business website is a place where all the transactions take place between a business organization and consumer directly (Miangiaracina, Marchet et al. 2015). In this model, a consumer visits the website and places an order to buy a catalog. The business organization, after receiving the order, will dispatch the goods to the customer. Successful examples like Amazon.com and Priceline.com are B2C leaders (Rappa 2008, Ta, Esper et al. 2015). Key features of this model are heavy advertising required to attract large customers, high investment of hardware and software, and good customer care service (Nica 2015)\n",
            "\n",
            "2.3 Supporting techniques The main supporting techniques for E-commerce logistics include E-commerce system, warehouse management system (WMS), and transportation management system (TMS). For a typical company which is able to carry out E-commerce business, an online system or platform is necessary. Large numbers of trading systems are in use nowadays. Customers then are able to search various merchandise. Therefore, a soft computing method was used to create a profile to examine how the events affect each other in an E-commerce system (Takacs et al., 2015). Ding (2013) presented a discussion about the application of business E-commerce platform in a mechanical processing enterprise to achieve green and sustainable development. This paper shows the possibility for small and medium-sized manufacturing companies to use the E-commerce system for boosting their products widely. Social commerce always relates to E-commerce which is undergoing an evolution using Web 2\n",
            "=============\n",
            "\n",
            "Question: In E-commerce, what are the two types of business models?\n",
            "Helpful Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: In E-commerce, what are the two types of business models?\n",
            "................................................................................\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #0\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7874481081962585\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "In the E-commerce LSCM, there are two major types of business models: business to consumer (B2C) and business to\n",
            "business (B2B) (Bolumole et al., 2015). In B2C model, business website is a place where all the transactions take place\n",
            "between a business organization and consumer directly (Mangiaracina et al., 2015). In this model, a consumer visits the\n",
            "website and places an order to buy the products. The business organization, after receiving the orders, will dispatch\n",
            "the goods to the customer. Successful examples like Amazon.com and Priceline.com are B2C leaders (Rappa, 2008; Ta et\n",
            "al., 2015). Key features of this model are heavy advertising required to attract large customers, high investment of\n",
            "hardware and software, and good customer care service (Nica, 2015). B2B refers to a situation where one business makes a\n",
            "commercial transaction with another, thus, the transaction volume of B2B is much higher than the volume of B2C\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #1\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7340328693389893\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "Based on the booming E-commerce, logistics and supply chain management (LSCM) has been greatly influenced when we are\n",
            "now already overwhelmed by its successes in both developed E- commerceLSCM,there are two major types of business models.\n",
            "They are business to consumer (B2C) and business to business (B2B) (Bolumole, Closset al.2015). In B2C model, business\n",
            "website is a place where all the transactions take place between a business organization and consumer directly\n",
            "(Miangiaracina, Marchet et al. 2015). In this model, a consumer visits the website and places an order to buy a catalog.\n",
            "The business organization, after receiving the order, will dispatch the goods to the customer. Successful examples like\n",
            "Amazon.com and Priceline.com are B2C leaders (Rappa 2008, Ta, Esper et al. 2015). Key features of this model are heavy\n",
            "advertising required to attract large customers, high investment of hardware and software, and good customer care\n",
            "service (Nica 2015)\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #2\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7162609100341797\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "2.3 Supporting techniques The main supporting techniques for E-commerce logistics include E-commerce system, warehouse\n",
            "management system (WMS), and transportation management system (TMS). For a typical company which is able to carry out\n",
            "E-commerce business, an online system or platform is necessary. Large numbers of trading systems are in use nowadays.\n",
            "Customers then are able to search various merchandise. Therefore, a soft computing method was used to create a profile\n",
            "to examine how the events affect each other in an E-commerce system (Takacs et al., 2015). Ding (2013) presented a\n",
            "discussion about the application of business E-commerce platform in a mechanical processing enterprise to achieve green\n",
            "and sustainable development. This paper shows the possibility for small and medium-sized manufacturing companies to use\n",
            "the E-commerce system for boosting their products widely. Social commerce always relates to E-commerce which is\n",
            "undergoing an evolution using Web 2\n",
            "................................................................................\n",
            "Response: The two types of business models in E-commerce are:  * **Business-to-consumer (B2C):** This model involves transactions\n",
            "between a business and individual consumers. Consumers visit the business website, place orders, and receive the goods\n",
            "directly. Examples of B2C businesses include Amazon and Priceline. * **Business-to-business (B2B):** This model involves\n",
            "transactions between businesses. The transaction volume in B2B is typically higher than in B2C.\n",
            "................................................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test Case II"
      ],
      "metadata": {
        "id": "li8OgPg7No5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"Give me B2C leaders?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEi9rNiQ-ehG",
        "outputId": "e60ab09c-f6f7-4cbc-e3c8-cdad1c6792cf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "Waiting\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant and subject matter expert helping the employees with their questions on supply chain industry, especially on the logistics domain.\n",
            "\n",
            "Question: Give me B2C leaders?\n",
            "\n",
            "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
            "\n",
            "Do not try to make up an answer:\n",
            " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
            " - If the context is empty, just say \"I do not know the answer to that.\"\n",
            "\n",
            "=============\n",
            "[47]. Ta, H., T. Esper and A. R. Hofer (2015). \"Business(cid:1)to(cid:1)Consumer (B2C) Collaboration: Rethinking the Role of Consumers in Supply Chain Management.\" Journal of Business Logistics 36(1): 133-134. [48]. Tan, K. H., Y. Zhan, G. Ji, F. Ye and C. Chang (2015). \"Harvesting big data to enhance supply chain innovation capabilities: An analytic infrastructure based on deduction graph.\" International Journal of Production Economics 165: 223-233.\n",
            "\n",
            "[31]. Li, J. and J. Ding (2014). \"Research of self-support logistics network synergy route and structure evolution--take SUNING and ZJS for examples.\" Journal of Beijing Jiaotong University(Social Sciences Edition)(03): 46-53.\n",
            "\n",
            "[49]. Timothy Thacher, B. W., Brian Stuorius (2007). Strategic Report For\n",
            "\n",
            "Lowe's Companies,Inc.\n",
            "\n",
            "[50]. Trebilcock, B. (2011). IKEA: Think global, act local for warehouse\n",
            "\n",
            "distribution. Modern Materials Handling. August.\n",
            "\n",
            "[32]. Liu, J. and Y. R. Hou (2011). \"Time based strategy in distribution\n",
            "\n",
            "In the E-commerce LSCM, there are two major types of business models: business to consumer (B2C) and business to business (B2B) (Bolumole et al., 2015). In B2C model, business website is a place where all the transactions take place between a business organization and consumer directly (Mangiaracina et al., 2015). In this model, a consumer visits the website and places an order to buy the products. The business organization, after receiving the orders, will dispatch the goods to the customer. Successful examples like Amazon.com and Priceline.com are B2C leaders (Rappa, 2008; Ta et al., 2015). Key features of this model are heavy advertising required to attract large customers, high investment of hardware and software, and good customer care service (Nica, 2015). B2B refers to a situation where one business makes a commercial transaction with another, thus, the transaction volume of B2B is much higher than the volume of B2C\n",
            "\n",
            "2. Guo ZX, Wong WK, Li M. A multivariate intelligent decision-making model for retail sales forecasting. Decis Sup- port Syst. 2013;55(1):247–55. https ://doi.org/10.1016/J.DSS.2013.01.026.\n",
            "\n",
            "3. Wei J-T, Lee M-C, Chen H-K, Wu H-H. Customer relationship management in the hairdressing industry: an applica- tion of data mining techniques. Expert Syst Appl. 2013;40(18):7513–8. https ://doi.org/10.1016/J.ESWA.2013.07.053. 4. Lu LX, Swaminathan JM. Supply chain management. Int Encycl Soc Behav Sci. 2015. https ://doi.org/10.1016/B978- 0-08-09708 6-8.73032 -7.\n",
            "\n",
            "5. Gholizadeh H, Tajdin A, Javadian N. A closed-loop supply chain robust optimization for disposable appliances. Neural Comput Appl. 2018. https ://doi.org/10.1007/s0052 1-018-3847-9.\n",
            "\n",
            "6. Tosarkani BM, Amin SH. A possibilistic solution to configure a battery closed-loop supply chain: multi-objective approach. Expert Syst Appl. 2018;92:12–26. https ://doi.org/10.1016/J.ESWA.2017.09.039.\n",
            "=============\n",
            "\n",
            "Question: Give me B2C leaders?\n",
            "Helpful Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: Give me B2C leaders?\n",
            "................................................................................\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #0\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7223916053771973\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "[47]. Ta, H., T. Esper and A. R. Hofer (2015). \"Business(cid:1)to(cid:1)Consumer (B2C) Collaboration: Rethinking the\n",
            "Role of Consumers in Supply Chain Management.\" Journal of Business Logistics 36(1): 133-134. [48]. Tan, K. H., Y. Zhan,\n",
            "G. Ji, F. Ye and C. Chang (2015). \"Harvesting big data to enhance supply chain innovation capabilities: An analytic\n",
            "infrastructure based on deduction graph.\" International Journal of Production Economics 165: 223-233.  [31]. Li, J. and\n",
            "J. Ding (2014). \"Research of self-support logistics network synergy route and structure evolution--take SUNING and ZJS\n",
            "for examples.\" Journal of Beijing Jiaotong University(Social Sciences Edition)(03): 46-53.  [49]. Timothy Thacher, B.\n",
            "W., Brian Stuorius (2007). Strategic Report For  Lowe's Companies,Inc.  [50]. Trebilcock, B. (2011). IKEA: Think global,\n",
            "act local for warehouse  distribution. Modern Materials Handling. August.  [32]. Liu, J. and Y. R. Hou (2011). \"Time\n",
            "based strategy in distribution\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #1\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7116405963897705\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "In the E-commerce LSCM, there are two major types of business models: business to consumer (B2C) and business to\n",
            "business (B2B) (Bolumole et al., 2015). In B2C model, business website is a place where all the transactions take place\n",
            "between a business organization and consumer directly (Mangiaracina et al., 2015). In this model, a consumer visits the\n",
            "website and places an order to buy the products. The business organization, after receiving the orders, will dispatch\n",
            "the goods to the customer. Successful examples like Amazon.com and Priceline.com are B2C leaders (Rappa, 2008; Ta et\n",
            "al., 2015). Key features of this model are heavy advertising required to attract large customers, high investment of\n",
            "hardware and software, and good customer care service (Nica, 2015). B2B refers to a situation where one business makes a\n",
            "commercial transaction with another, thus, the transaction volume of B2B is much higher than the volume of B2C\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #2\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7094653248786926\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "2. Guo ZX, Wong WK, Li M. A multivariate intelligent decision-making model for retail sales forecasting. Decis Sup- port\n",
            "Syst. 2013;55(1):247–55. https ://doi.org/10.1016/J.DSS.2013.01.026.  3. Wei J-T, Lee M-C, Chen H-K, Wu H-H. Customer\n",
            "relationship management in the hairdressing industry: an applica- tion of data mining techniques. Expert Syst Appl.\n",
            "2013;40(18):7513–8. https ://doi.org/10.1016/J.ESWA.2013.07.053. 4. Lu LX, Swaminathan JM. Supply chain management. Int\n",
            "Encycl Soc Behav Sci. 2015. https ://doi.org/10.1016/B978- 0-08-09708 6-8.73032 -7.  5. Gholizadeh H, Tajdin A, Javadian\n",
            "N. A closed-loop supply chain robust optimization for disposable appliances. Neural Comput Appl. 2018. https\n",
            "://doi.org/10.1007/s0052 1-018-3847-9.  6. Tosarkani BM, Amin SH. A possibilistic solution to configure a battery\n",
            "closed-loop supply chain: multi-objective approach. Expert Syst Appl. 2018;92:12–26. https\n",
            "://doi.org/10.1016/J.ESWA.2017.09.039.\n",
            "................................................................................\n",
            "Response: Based on the provided context, here are some B2C leaders:  * **Amazon.com:** A global e-commerce giant known for its\n",
            "wide selection of products, competitive prices, and fast shipping. * **Priceline.com:** A leading online travel agency\n",
            "offering deals on flights, hotels, and rental cars.  These companies are successful examples of B2C leaders due to their\n",
            "heavy advertising, high investment in technology, and excellent customer service.\n",
            "................................................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test Case III"
      ],
      "metadata": {
        "id": "kUKA_DzmNrpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"What are primary activities and support activities?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkceuoSbHeJ1",
        "outputId": "08147e9f-62ca-4759-acb5-e477397e8008"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "Waiting\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant and subject matter expert helping the employees with their questions on supply chain industry, especially on the logistics domain.\n",
            "\n",
            "Question: What are primary activities and support activities?\n",
            "\n",
            "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
            "\n",
            "Do not try to make up an answer:\n",
            " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
            " - If the context is empty, just say \"I do not know the answer to that.\"\n",
            "\n",
            "=============\n",
            "Porter distinguishes between primary activities and support activities. Primary activities are directly concerned with the creation or delivery of a product or service. They can be grouped into five main areas: inbound logistics, operations, outbound logistics, marketing and sales, and service. Each of these primary activities is linked to support activities which help to improve their effectiveness or efficiency. There are four main areas of support activities: procurement, technology development (including R&D), human resource management, and infrastructure (systems for planning, finance, quality, information management, etc.). This study seeks to investigate the inter-relationships between the key primary activities of a firm’s value chain – particularly, the inbound supply chain processes and internal production processes of firms and their implications on inbound and competitive performance outcomes.\n",
            "\n",
            "Although the problem of service level and of proper definition of stock levels has mainly been addressed in the streams of research mentioned above, studies in the field of warehouse management have pointed out some other factors that can influence such performance. Frazelle there are three main categories of (2002) claims that warehouse performance: productivity, which measures the level of asset utilization; quality, thought of as the level of accuracy in order picking and shipping; cycle time, i.e. the responsiveness of order picking and shipping. Such performance categories, which are consistent with the ones peculiar to the logistic process as a whole (Rushton et al. 2006), can be deeply influenced by the way in which\n",
            "\n",
            "29\n",
            "\n",
            "30\n",
            "\n",
            "3.2. Organisation of the review of applications\n",
            "\n",
            "We review and classify applications of RL into two categories: logistics and SCM. Under logistics, the applications are related to the detailed operational plans to guide the movements of products and goods. Under SCM, the applications include other relevant processes to enable the delivery of products and goods from the beginning of the SC to the final consumers.\n",
            "\n",
            "The reviewed articles can be characterised by three dimensions: application domains, levels of decisions (if possible), and methodologies. Articles are first categorised by their applications and then levels of decisions (if any), where methodologies are discussed. Characteristics of the reviewed articles under the same application are summarised at the end of the subsection.\n",
            "\n",
            "3.3. Logistics\n",
            "\n",
            "Under logistics, we further categorise research studies according to the application domain.\n",
            "\n",
            "3.3.1. Travelling salesman problem and vehicle routing problem\n",
            "=============\n",
            "\n",
            "Question: What are primary activities and support activities?\n",
            "Helpful Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: What are primary activities and support activities?\n",
            "................................................................................\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #0\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7816859483718872\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "Porter distinguishes between primary activities and support activities. Primary activities are directly concerned with\n",
            "the creation or delivery of a product or service. They can be grouped into five main areas: inbound logistics,\n",
            "operations, outbound logistics, marketing and sales, and service. Each of these primary activities is linked to support\n",
            "activities which help to improve their effectiveness or efficiency. There are four main areas of support activities:\n",
            "procurement, technology development (including R&D), human resource management, and infrastructure (systems for\n",
            "planning, finance, quality, information management, etc.). This study seeks to investigate the inter-relationships\n",
            "between the key primary activities of a firm’s value chain – particularly, the inbound supply chain processes and\n",
            "internal production processes of firms and their implications on inbound and competitive performance outcomes.\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #1\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.6797133684158325\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "Although the problem of service level and of proper definition of stock levels has mainly been addressed in the streams\n",
            "of research mentioned above, studies in the field of warehouse management have pointed out some other factors that can\n",
            "influence such performance. Frazelle there are three main categories of (2002) claims that warehouse performance:\n",
            "productivity, which measures the level of asset utilization; quality, thought of as the level of accuracy in order\n",
            "picking and shipping; cycle time, i.e. the responsiveness of order picking and shipping. Such performance categories,\n",
            "which are consistent with the ones peculiar to the logistic process as a whole (Rushton et al. 2006), can be deeply\n",
            "influenced by the way in which  29  30\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #2\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.6642796993255615\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "3.2. Organisation of the review of applications  We review and classify applications of RL into two categories:\n",
            "logistics and SCM. Under logistics, the applications are related to the detailed operational plans to guide the\n",
            "movements of products and goods. Under SCM, the applications include other relevant processes to enable the delivery of\n",
            "products and goods from the beginning of the SC to the final consumers.  The reviewed articles can be characterised by\n",
            "three dimensions: application domains, levels of decisions (if possible), and methodologies. Articles are first\n",
            "categorised by their applications and then levels of decisions (if any), where methodologies are discussed.\n",
            "Characteristics of the reviewed articles under the same application are summarised at the end of the subsection.  3.3.\n",
            "Logistics  Under logistics, we further categorise research studies according to the application domain.  3.3.1.\n",
            "Travelling salesman problem and vehicle routing problem\n",
            "................................................................................\n",
            "Response: ## Primary Activities and Support Activities  Porter's Value Chain framework distinguishes between **primary\n",
            "activities** and **support activities**.  **Primary activities** are directly involved in the creation or delivery of a\n",
            "product or service. They can be grouped into five main areas:  * **Inbound logistics:** Receiving and storing raw\n",
            "materials and other inputs. * **Operations:** Transforming inputs into finished products or services. * **Outbound\n",
            "logistics:** Delivering finished products or services to customers. * **Marketing and sales:** Promoting and selling\n",
            "products or services to customers. * **Service:** Providing after-sales support to customers.  **Support activities**\n",
            "help to improve the effectiveness or efficiency of primary activities. They can be grouped into four main areas:  *\n",
            "**Procurement:** Acquiring raw materials and other inputs. * **Technology development:** Developing and implementing new\n",
            "technologies. * **Human resource management:** Recruiting, training, and managing employees. * **Infrastructure:**\n",
            "Providing the physical and organizational infrastructure necessary to support the other activities.  **Relationship\n",
            "between primary and support activities:**  * Support activities play a vital role in supporting and enhancing the\n",
            "effectiveness of primary activities.  * For example, efficient procurement can ensure that raw materials are available\n",
            "when needed, while effective human resource management can ensure that employees have the skills and training necessary\n",
            "to perform their jobs effectively. * By optimizing both primary and support activities, businesses can improve their\n",
            "overall efficiency and effectiveness.  **Additional notes:**  * The specific primary and support activities that are\n",
            "most important for a particular business will vary depending on the industry and the nature of the business. * It is\n",
            "important for businesses to regularly review and assess their primary and support activities to ensure that they are\n",
            "aligned with their overall business goals and objectives.\n",
            "................................................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test Case IV"
      ],
      "metadata": {
        "id": "8l3Jm0oDNtKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"Since when has supply chain management received attention?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPXV4oohNV9_",
        "outputId": "927e0fb7-2b36-4747-ec07-bc2077826eb0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "Waiting\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant and subject matter expert helping the employees with their questions on supply chain industry, especially on the logistics domain.\n",
            "\n",
            "Question: Since when has supply chain management received attention?\n",
            "\n",
            "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
            "\n",
            "Do not try to make up an answer:\n",
            " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
            " - If the context is empty, just say \"I do not know the answer to that.\"\n",
            "\n",
            "=============\n",
            "Supply chain management and other similar terms, such as network sourcing, supply pipeline management, value chain management, and value stream management have become subjects of increasing interest in recent years, to academics, consultants and business manage- ment (Christopher, 1992; Hines, 1994; Lamming, 1996; Saunders, 1995, 1998). It is recognised in some parts of the literature that the supply chain should be seen as the central unit of competitive analysis (Macbeth and\n",
            "\n",
            "Corresponding author. Tel.: #1-203-528222; fax: #1-203-404175.\n",
            "\n",
            "0969-7012/00/$ - see front matter ( 2000 Elsevier Science Ltd. All rights reserved. PII: S 0 9 6 9 - 7 0 1 2 ( 9 9 ) 0 0 0 3 0 - 1\n",
            "\n",
            "68\n",
            "\n",
            "S. Croom et al. / European Journal of Purchasing & Supply Management 6 (2000) 67}83\n",
            "\n",
            "s w e n d n a s g o B\n",
            "\n",
            "l\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "o d u a e c o v s g o\n",
            "\n",
            "i\n",
            "\n",
            "i\n",
            "\n",
            "l\n",
            "\n",
            "l l\n",
            "\n",
            "a C\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "g n i s n e s\n",
            "\n",
            "s g n h t\n",
            "\n",
            "i\n",
            "\n",
            "f\n",
            "\n",
            "o t e n r e t n\n",
            "\n",
            "I\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "D F R\n",
            "\n",
            "I\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "s g o\n",
            "\n",
            "l\n",
            "\n",
            "r e t n e c\n",
            "\n",
            "l l\n",
            "\n",
            "a C\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "s d r o c e r\n",
            "\n",
            "l i\n",
            "\n",
            "a m E\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "a t a d n o i t c a s n a r t P R E\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "a t a d d e t a r e n e g - e n h c a M\n",
            "\n",
            "i\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "y t i l i\n",
            "\n",
            "b a\n",
            "\n",
            "l i\n",
            "\n",
            "a v a - f l e h s - n O\n",
            "\n",
            "Page 6 of 22\n",
            "\n",
            "Seyedan and Mafakheri J Big Data (2020) 7:53\n",
            "\n",
            "Demand management in supply chains\n",
            "\n",
            "The term “demand management” emerged in practice in the late 1980s and early 1990s. Traditionally, there are two approaches for demand management. A forward approach which looks at potential demand over the next several years and a backward approach that relies on past or ongoing capabilities in responding to demand [50].\n",
            "\n",
            "Logistics and supply chain management (SCM) can be regarded as the processes of moving products and goods from production (suppliers) to consumption (customers). The problems in logistics and SCM have always been an important subject in the civil and military domains since the 20th century BC (Ghiani et al., 2013). Since the last century, with the introduction to operational research and computers, various optimisation models and algorithms have been proposed and applied, such that the problems in logistics and SCM can be solved systematically and scientifically. More recently, with the advancements in data and computer sciences, we have been witnessing the growth in applications of reinforcement learning (RL) for solving decision problems. Typically, these decision problems involve large state and decision spaces with uncertainties in the system. Due to the complexities of logistics and supply chain (SC) systems, RL has also gained greater popularity in this domain in recent years.\n",
            "=============\n",
            "\n",
            "Question: Since when has supply chain management received attention?\n",
            "Helpful Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: Since when has supply chain management received attention?\n",
            "................................................................................\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #0\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7938569784164429\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "Supply chain management and other similar terms, such as network sourcing, supply pipeline management, value chain\n",
            "management, and value stream management have become subjects of increasing interest in recent years, to academics,\n",
            "consultants and business manage- ment (Christopher, 1992; Hines, 1994; Lamming, 1996; Saunders, 1995, 1998). It is\n",
            "recognised in some parts of the literature that the supply chain should be seen as the central unit of competitive\n",
            "analysis (Macbeth and  Corresponding author. Tel.: #1-203-528222; fax: #1-203-404175.  0969-7012/00/$ - see front matter\n",
            "( 2000 Elsevier Science Ltd. All rights reserved. PII: S 0 9 6 9 - 7 0 1 2 ( 9 9 ) 0 0 0 3 0 - 1  68  S. Croom et al. /\n",
            "European Journal of Purchasing & Supply Management 6 (2000) 67}83\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #1\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.763698160648346\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "s w e n d n a s g o B  l              o d u a e c o v s g o  i  i  l  l l  a C              g n i s n e s  s g n h t  i\n",
            "f  o t e n r e t n  I              D F R  I                  s g o  l  r e t n e c  l l  a C                s d r o c e\n",
            "r  l i  a m E                a t a d n o i t c a s n a r t P R E                  a t a d d e t a r e n e g - e n h c a\n",
            "M  i                  y t i l i  b a  l i  a v a - f l e h s - n O  Page 6 of 22  Seyedan and Mafakheri J Big Data\n",
            "(2020) 7:53  Demand management in supply chains  The term “demand management” emerged in practice in the late 1980s and\n",
            "early 1990s. Traditionally, there are two approaches for demand management. A forward approach which looks at potential\n",
            "demand over the next several years and a backward approach that relies on past or ongoing capabilities in responding to\n",
            "demand [50].\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #2\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7570062875747681\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "Logistics and supply chain management (SCM) can be regarded as the processes of moving products and goods from\n",
            "production (suppliers) to consumption (customers). The problems in logistics and SCM have always been an important\n",
            "subject in the civil and military domains since the 20th century BC (Ghiani et al., 2013). Since the last century, with\n",
            "the introduction to operational research and computers, various optimisation models and algorithms have been proposed\n",
            "and applied, such that the problems in logistics and SCM can be solved systematically and scientifically. More recently,\n",
            "with the advancements in data and computer sciences, we have been witnessing the growth in applications of reinforcement\n",
            "learning (RL) for solving decision problems. Typically, these decision problems involve large state and decision spaces\n",
            "with uncertainties in the system. Due to the complexities of logistics and supply chain (SC) systems, RL has also gained\n",
            "greater popularity in this domain in recent years.\n",
            "................................................................................\n",
            "Response: The text mentions that supply chain management has received increasing attention from academics, consultants, and\n",
            "business management in recent years. The specific timeframe mentioned is not provided, but it is stated that this trend\n",
            "started in the late 1980s and early 1990s.\n",
            "................................................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test Case V"
      ],
      "metadata": {
        "id": "X2HFnA9HNvPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"What has caused perishable products to have limited shelf lives with continuous and significant deterioration in the quality value over time in all stages of the supply chain? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXcCEijwNaqc",
        "outputId": "07330c66-6d0d-4c4d-d71b-0b1422042120"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "Waiting\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant and subject matter expert helping the employees with their questions on supply chain industry, especially on the logistics domain.\n",
            "\n",
            "Question: What has caused perishable products to have limited shelf lives with continuous and significant deterioration in the quality value over time in all stages of the supply chain? \n",
            "\n",
            "Strictly Use ONLY the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
            "\n",
            "Do not try to make up an answer:\n",
            " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
            " - If the context is empty, just say \"I do not know the answer to that.\"\n",
            "\n",
            "=============\n",
            "Perishable products have limited shelf lives with continuous and significant deterioration in the quality value over time in all stages of the supply chain, from food processing, to distribution, to retail, until final consumption. This could be due to temperature, humidity, pos- sible interaction effects between food products, shock during trans- portation, etc (Blackburn & Scudder, 2009). Hence, one of the most important considerations in guaranteeing food quality, health, and safety is the distribution management of food products including all types; fresh, refrigerated, and frozen. As such, considering all these\n",
            "\n",
            "Discrete Dynamics in Nature and Society\n",
            "\n",
            "proteins stay the same, but lipids might get rancid. Meat products, as a special commodity, have cross-industry and cross-region features. As a result, the supply chain for beef products is more stringent. However, due to the current state of the global logistics supply chain, the hidden danger of meat food safety has increased. As a result, it is critical to integrate the food supply chain process, achieve vertical supply chain integration, optimize the process of the entire food supply chain, and reduce supply time. So the data analytics can provide a better opportunity to tackle both problems i.e., the optimization and reduction of carbon footprints.Quality-controlled logistics for perishable com- modities that take into consideration supplier decisions to send out alternative shipments, engineers to make changes, and the possibility of customers seeking an alternative provider.\n",
            "\n",
            "Data Availability\n",
            "\n",
            "N. Al Theeb, et al.\n",
            "\n",
            "the end users during a specific time, as fresh products. If some of ma- terials are not sold during the specific time, they must be stored in expensive deep-freezing refrigerators. The lack of advanced and effi- cient storage and transportation facilities of fresh products can cause greater losses. For example, in China, about 15% of all perishable products are transported in refrigerated vehicles, resulting in a loss up to $8.9 billion annually in fruit and vegetable distribution (Bolton & Liu, 2006). Additionally, delivering high amounts of some products could cause high inventory, and consequently high holding cost due to the cooling of refrigerated and frozen stores. On the other hand, deli- vering low quantities could yield to shortage in inventory and missing possible profit.\n",
            "=============\n",
            "\n",
            "Question: What has caused perishable products to have limited shelf lives with continuous and significant deterioration in the quality value over time in all stages of the supply chain? \n",
            "Helpful Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: What has caused perishable products to have limited shelf lives with continuous and significant deterioration in the quality value over time in all stages of the supply chain? \n",
            "................................................................................\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #0\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.8652812242507935\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "Perishable products have limited shelf lives with continuous and significant deterioration in the quality value over\n",
            "time in all stages of the supply chain, from food processing, to distribution, to retail, until final consumption. This\n",
            "could be due to temperature, humidity, pos- sible interaction effects between food products, shock during trans-\n",
            "portation, etc (Blackburn & Scudder, 2009). Hence, one of the most important considerations in guaranteeing food\n",
            "quality, health, and safety is the distribution management of food products including all types; fresh, refrigerated,\n",
            "and frozen. As such, considering all these\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #1\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7616720199584961\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "Discrete Dynamics in Nature and Society  proteins stay the same, but lipids might get rancid. Meat products, as a\n",
            "special commodity, have cross-industry and cross-region features. As a result, the supply chain for beef products is\n",
            "more stringent. However, due to the current state of the global logistics supply chain, the hidden danger of meat food\n",
            "safety has increased. As a result, it is critical to integrate the food supply chain process, achieve vertical supply\n",
            "chain integration, optimize the process of the entire food supply chain, and reduce supply time. So the data analytics\n",
            "can provide a better opportunity to tackle both problems i.e., the optimization and reduction of carbon\n",
            "footprints.Quality-controlled logistics for perishable com- modities that take into consideration supplier decisions to\n",
            "send out alternative shipments, engineers to make changes, and the possibility of customers seeking an alternative\n",
            "provider.  Data Availability\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #2\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.74818354845047\n",
            "Document Source: adta5760-docs-folder-2/pdfs\n",
            "................................................................................\n",
            "Content: \n",
            "N. Al Theeb, et al.  the end users during a specific time, as fresh products. If some of ma- terials are not sold during\n",
            "the specific time, they must be stored in expensive deep-freezing refrigerators. The lack of advanced and effi- cient\n",
            "storage and transportation facilities of fresh products can cause greater losses. For example, in China, about 15% of\n",
            "all perishable products are transported in refrigerated vehicles, resulting in a loss up to $8.9 billion annually in\n",
            "fruit and vegetable distribution (Bolton & Liu, 2006). Additionally, delivering high amounts of some products could\n",
            "cause high inventory, and consequently high holding cost due to the cooling of refrigerated and frozen stores. On the\n",
            "other hand, deli- vering low quantities could yield to shortage in inventory and missing possible profit.\n",
            "................................................................................\n",
            "Response: The limited shelf life of perishable products is caused by a combination of factors that occur throughout the supply\n",
            "chain, from production to consumption. These factors can be categorized into two main groups:  **1. Biological\n",
            "factors:**  * **Microbial growth:** Microorganisms such as bacteria, yeast, and mold can contaminate perishable products\n",
            "and cause spoilage. These microorganisms thrive in warm, humid environments and can multiply rapidly, leading to rapid\n",
            "deterioration of the product's quality. * **Enzymatic activity:** Enzymes naturally present in perishable products can\n",
            "break down the product's components over time, leading to changes in texture, flavor, and appearance. * **Physiological\n",
            "processes:** Perishable products continue to respire after harvest or slaughter, consuming oxygen and releasing carbon\n",
            "dioxide. This process can lead to the depletion of nutrients and the buildup of undesirable byproducts, affecting the\n",
            "product's quality.  **2. Environmental factors:**  * **Temperature:** Temperature fluctuations can significantly impact\n",
            "the shelf life of perishable products. High temperatures accelerate microbial growth and enzymatic activity, while low\n",
            "temperatures can cause chilling injury or freezing damage. * **Humidity:** High humidity can promote microbial growth\n",
            "and encourage the development of mold. Conversely, low humidity can cause dehydration and shrinkage of the product. *\n",
            "**Physical damage:** Mechanical damage during handling, transportation, and storage can bruise or puncture the product,\n",
            "creating entry points for microorganisms and accelerating spoilage. * **Exposure to light:** Light can cause\n",
            "discoloration and oxidation in some perishable products, affecting their appearance and flavor.  These factors interact\n",
            "and contribute to the continuous and significant deterioration of perishable products throughout the supply chain.\n",
            "Understanding these factors is crucial for developing strategies to extend the shelf life of perishable products and\n",
            "minimize losses.  Here are some specific examples of how these factors can impact different types of perishable\n",
            "products:  * **Fruits and vegetables:** These products are highly susceptible to microbial spoilage and enzymatic\n",
            "browning. Maintaining proper temperature and humidity control during storage and transportation is essential for\n",
            "extending their shelf life. * **Meat and poultry:** These products are susceptible to bacterial contamination and\n",
            "oxidation. Proper handling, chilling, and packaging are crucial for maintaining their safety and quality. * **Dairy\n",
            "products:** These products are susceptible to microbial spoilage and fermentation. Maintaining proper refrigeration and\n",
            "using appropriate packaging can help to extend their shelf life.  By understanding the factors that contribute to the\n",
            "limited shelf life of perishable products, we can develop strategies to mitigate their impact and improve the efficiency\n",
            "and sustainability of the supply chain.\n",
            "................................................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMAGdIAtNeKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}